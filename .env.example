# .env.example - Copy this to .env and fill in your values

# --- Required ---
# Set a descriptive user agent for Nominatim (OpenStreetMap) geocoding
# Replace with your application name and contact email/URL as per Nominatim's policy
GEOCODING_USER_AGENT="MyEidoAgentPOC/1.0 (klimentlamh@gmail.com)"

# --- LLM Configuration ---
# Choose ONE way to configure the LLM (or leave defaults for placeholder)


# Option A: Use a cloud API (e.g., DeepSeek - Requires API Key)
# LLM_MODEL_NAME="deepseek-chat"
# LLM_API_KEY=""
# LLM_API_BASE_URL="https://api.deepseek.com/v1" # Example, check DeepSeek docs

# Option B: Use a locally hosted LLM (via Ollama, LM Studio, vLLM etc.) - Set API Base URL
# LLM_MODEL_NAME="llama3:latest" # Model name recognized by your local server
# LLM_API_BASE_URL="http://localhost:11434/v1" # Example Ollama URL (check your setup)
# LLM_API_KEY="ollama" # Often required even if not authenticated, depends on server

# Option C: Use Hugging Face model loaded directly (transformers library)
# LLM_MODEL_NAME="Qwen/Qwen1.5-7B-Chat-GGUF" # Example - specify path or HF identifier recognized by your llm_interface logic
# Note: LLM_API_KEY and LLM_API_BASE_URL would likely be ignored if llm_interface loads locally.

# Option D: Use the Placeholder/Rule-based (Default if nothing else set)
# LLM_MODEL_NAME="PlaceholderLLM"

# --- Embedding Model ---
# Specify the SentenceTransformer model name or path
# EMBEDDING_MODEL_NAME="all-MiniLM-L6-v2" # Default, fast, good baseline
# EMBEDDING_MODEL_NAME="all-mpnet-base-v2" # Larger, potentially better
# EMBEDDING_MODEL_NAME="path/to/your/local/embedding_model"

# --- Incident Matching Parameters (Optional - Defaults are in config/settings.py) ---
# SIMILARITY_THRESHOLD=0.75
# TIME_WINDOW_MINUTES=90
# DISTANCE_THRESHOLD_KM=1.5

# --- API/UI Server Ports (Optional - Defaults are in config/settings.py) ---
# API_PORT=8001
# STREAMLIT_SERVER_PORT=8502

# --- Logging ---
# LOG_LEVEL="DEBUG" # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL