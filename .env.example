# ---------------------------------------------------------------
# EIDO Sentinel Environment Variables (.env.example)
# Copy this file to .env and fill in your values.
# Lines starting with # are comments.
# ---------------------------------------------------------------

# --- Application Settings ---
# Base URL for the FastAPI backend. Used by Streamlit UI.
# Example for local dev: API_BASE_URL="http://localhost:8000"
# Example for Render deployment: API_BASE_URL="https://your-render-app-name.onrender.com"
API_BASE_URL="http://localhost:8000"

# --- Database ---
# Connection string for PostgreSQL database.
# Example for local Docker: DATABASE_URL="postgresql+asyncpg://user:password@localhost:5432/eido_sentinel_db"
# On Render, this will be provided by the PostgreSQL service.
DATABASE_URL="postgresql+asyncpg://user:password@localhost:5432/eido_sentinel_db"

# --- Logging ---
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# --- LLM Configuration ---
# Select the main LLM provider: 'google', 'openrouter', 'local', 'none'
# 'none' disables LLM features (parsing, summary, actions).
# 'local' requires LOCAL_LLM_API_BASE_URL and LOCAL_LLM_MODEL_NAME to be set.
LLM_PROVIDER="google"

# --- Google Generative AI ---
# Required if LLM_PROVIDER=google
GOOGLE_API_KEY=""
# Optional: Specify model (see config/settings.py for defaults/options)
# Ensure this model is available for your API key and region.
# "gemini-2.0-flash" is a capable and cost-effective model.
# "gemini-1.0-pro" is a stable, generally available model.
GOOGLE_MODEL_NAME="gemini-2.0-flash"

# --- OpenRouter ---
# Required if LLM_PROVIDER=openrouter
OPENROUTER_API_KEY=""
OPENROUTER_MODEL_NAME="openai/gpt-4o-mini" # Example: Use a fast/cheap model
OPENROUTER_API_BASE_URL="https://openrouter.ai/api/v1"

# --- Local LLM (Ollama, LM Studio, etc. via OpenAI compatible API) ---
# Required if LLM_PROVIDER=local
LOCAL_LLM_API_BASE_URL="http://localhost:11434/v1" # Example for Ollama
# LOCAL_LLM_API_BASE_URL="http://localhost:1234/v1" # Example for LM Studio (ensure server is running with OpenAI API preset)
LOCAL_LLM_MODEL_NAME="llama3:latest" # Example: Needs to match model served locally
# Optional: API key if your local server needs one (often not needed)
LOCAL_LLM_API_KEY="ollama" # Or "EMPTY" or the actual key

# --- Embedding Service ---
# Model name for sentence-transformers
EMBEDDING_MODEL_NAME="all-MiniLM-L6-v2"

# --- Geocoding Service (Nominatim/OpenStreetMap) ---
# REQUIRED: Set a unique User-Agent including contact info (email) per Nominatim's policy
GEOCODING_USER_AGENT="EidoSentinelApp/0.9 (contact: your_email@example.com)" # Updated version

# --- Incident Matching Parameters ---
SIMILARITY_THRESHOLD=0.70
TIME_WINDOW_MINUTES=60
DISTANCE_THRESHOLD_KM=1.0

# --- API Server Configuration (Optional) ---
# These are used if you run api/main.py directly.
# On Render, HOST will be 0.0.0.0 and PORT will be set by Render ($PORT).
API_HOST="127.0.0.1"
API_PORT=8000

# --- Streamlit UI Port (Optional) ---
# STREAMLIT_SERVER_PORT=8501